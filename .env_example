# Local LLM configuration
LLM_MODEL_PATH=
LLM_CTX_SIZE=4096
LLM_N_THREADS=4
LLM_MAX_TOKENS=768
LLM_TEMPERATURE=0.7

# Optional cloud LLMs (one of these can be set to run live without local models)
# OpenAI-compatible text generation server (e.g., LM Studio, OpenRouter, OpenAI-compatible OSS endpoints)
TEXTGEN_BASE_URL=
TEXTGEN_API_KEY=
TEXTGEN_MODEL=gpt-5

# Hugging Face Inference API (requires a free HF token and a public model)
HUGGINGFACE_API_TOKEN=
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2

# Stable Diffusion WebUI (optional)
SD_WEBUI_URL=http://127.0.0.1:7860

# Outputs
OUTPUT_ROOT=outputs

